{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "479bfab7",
   "metadata": {},
   "source": [
    "# 9.1 심층신경망\n",
    "\n",
    "비선형 함수 형태를 근사계산할때 선형 회귀 모델과 로지스틱 회귀 모델로는 비선형 문제를 해결할 수 없다.  \n",
    "심층신경망은 이러한 문제를 해결할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c5189b",
   "metadata": {},
   "source": [
    "### 1. 심층신경망이란?\n",
    "\n",
    "심층신경망은 서로 다른 선형 계층을 깊게 쌓아 구성할 수 있다.\n",
    "\n",
    "<img src = \"심층신경망1.jpg\" width = \"300\" height = \"300\">\n",
    "\n",
    "위 수식과 같이 두 개의 선형 게층을 가진 모델을 지닌 선형 계층은 심층신경망이 되지 않는다.\n",
    "\n",
    "<img src = \"심층신경망2.jpg\" width = \"300\" height = \"300\">\n",
    "두 선형 계층을 통과하는 것은 또 다른 하나의 선형 계층을 통과하는 것과 같다.\n",
    "\n",
    "비선형 문제를 풀 수 있는 가장 간단한 방법으로 선형 계층을 쌓을 때 그 사이에 시그모이드같은 비선형 함수를 끼워 넣는 것이 있다.  \n",
    "꼭 시그모이드나 탄에이치일 필요는 없다.  \n",
    "되도록이면 단조증가 형태의 비선형 함수이면 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb56212",
   "metadata": {},
   "source": [
    "<img src = \"심층신경망3.jpg\" width = \"450\" height = \"450\">\n",
    "이와 같이 심층신경망을 구성하여 복잡한 비선형 데이터의 관계를 학습하거나 문제를 해결할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c5486",
   "metadata": {},
   "source": [
    "###  2. 심층신경망의 크기\n",
    "\n",
    "심층신경망의 깊이와 너비를 조절하여 복잡한 형태의 데이터 관계나 문제를 해결할 수 있도록 할 수 있다.  \n",
    "보통 신경망을 구성할 때 계층이 진행될수록 너비가 줄어드는 형태로 설계를 하지만 깊이가 깊어지거나 너비가 넓어지게 되면 가중치 파라미터 크기가 늘어나게 되면서, 경사하강법을 통해 최적화 해야하는 공간의 차원 크기도 같이 늘어나게 된다.  \n",
    "따라서 적절한 신경망의 크기를 정해주어 신경망이 데이터의 관계를 배우는데 최적화가 잘 진행될 수 있도록 도와주는것이 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca2f1d",
   "metadata": {},
   "source": [
    "# 9.2 심층신경망의 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ad2302",
   "metadata": {},
   "source": [
    "### 1. 심층신경망의 학습 개요\n",
    "\n",
    "심층신경망을 구성하는 여러 계층의 가중치 파라미터들로 손실 함수를 미분하고, 그 결과를 경사하강법에 활용하여 각 가중치 파라미터를 업데이트한다.  \n",
    "\n",
    "<img src = \"심층신경망4.jpg\" width = \"400\" height = \"400\">\n",
    "\n",
    "하지만 다음 그림과 같이 심층신경망은 계층이 많아진 만큼, 가중치 파라미터도 늘어나기 대문에 손실 함수에 대해 미분을 해야하는 일도 늘어나게 된다.\n",
    "\n",
    "<img src = \"심층신경망5.jpg\" width = \"400\" height = \"400\">\n",
    "위 그림과 같이, W1과 같이 입력으로부터 가까운 계층의 파라미터일수록 손실 함수의 수식을 전개해서 W1로 표현할 때 더 복잡한 함수 꼴이 된다.  \n",
    "이것을 미분하는 일은 신경망이 깊어질수록 점점 더 비효율적이게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40aff199",
   "metadata": {},
   "source": [
    "### 2. 역전파\n",
    "\n",
    "우리는 역전파 알고리즘을 통해 효율적으로 심층신경망을 학습시킬 수 있다.  \n",
    "예를들어 y=g○f(x)와 같은 합성 함수가 있다고 가정하자.  \n",
    "이때 매개변수 h를 추가하여 다음과 같이 표현할 수 있다.\n",
    "<img src = \"심층신경망6.jpg\" width = \"300\" height = \"300\">\n",
    "수행하고자 하는 y를 x로 미분하는 작업은 체일 루에 의해서 y를 h로 미분한 값에 h를 x로 미분한 값을 곱하는 것과 같아진다.\n",
    "<img src = \"심층신경망7.jpg\" width = \"300\" height = \"300\">\n",
    "\n",
    "이런 성질을 이용하여 심층신경망의 미분도 간단한 수식에 대한 미분의 곱으로 표현된다.  \n",
    "다음 그림과 같이 미분 계산 과정이 계속해서 뒤 쪽 계층으로 전달되는 것처럼 보이며 이것을 역전파라고 부른다.\n",
    "<img src = \"심층신경망8.jpg\" width = \"400\" height = \"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f90ea54",
   "metadata": {},
   "source": [
    "# 9.3 역전파 알고리즘의 수식\n",
    "\n",
    "심층신경망을 활용하여 회귀문제를 풀고자 할 때, 다음 수식과 같이 MSE손실 함수를 활용할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
