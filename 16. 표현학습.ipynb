{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.1 특징(feature)란?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 특징\n",
    "\n",
    "모델은 원하는 출력 결과를 도출하는 입력 샘플을 다른 샘플들과 구분해낼 수 있는 능력이 필요하다. 따라서 데이터의 샘플을 잘 나타내는 특징을 추출하고 학습할 수 있어야 한다.  \n",
    "MNIST 데이터셋 예제에서는 데이터 샘플의 숫자를 분류하기 위해서 다음과 같은 정보들이 필요할 것 이다.\n",
    "* 곧은 선과 휘어진 선이 얼마나 있는가?\n",
    "* 곧은 선과 휘어진 선들이 서로 어떻게 이어져 있는가?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 특징 추출 방법: 머신러닝 vs 딥러닝\n",
    "\n",
    "전통적인 방식의 머신러닝에서는 주로 사람이 직접 가정을 세우고 특징을 추출하는 방법을 설정한다.  \n",
    "이를 위해서 데이터를 면밀하게 분석하는 과정을 거쳐야 하고, 어떠한 가정에 따라 전처리를 수행하여 특징을 추출할 수 있다.  \n",
    "장점으로는 모델의 동작 및 결과 해석을 하기 쉽다. 단점으로는 가설의 설정이 잘못되거나 미처 생각하지 못한 특징이 존재할 수 있다는 리스크도 존재한다.\n",
    "\n",
    "딥러닝을 활용한 학습 수행의 경우에는 데이터를 날(raw)것의 상태로 넣어준다. 그리고 신경망 모델이 직접 특징을 파악하고 추출하는 과정을 거쳐 분류 또는 회귀 작업을 수행한다.  \n",
    "장점으로는 구현이 용이하며 사람이 발견할 수 없는 특징들도 활용할 수 있다는 장점이 있다. 딥러닝이 뛰어난 성능을 보여주는 이유 중 하나일 것 이다.  \n",
    "단점으로는 딥러닝 모델은 내부적으로 스스로 추출하고 가공한 특징을 활용하기 때문에 이를 해석하기 어렵다는 것이다. 따라서 모델의 성능이 만족스럽지 않을 때는 원인을 분석하는 데 어려움을 겪을 가능성이 높다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 특징 벡터\n",
    "\n",
    "특징 벡터(feature vector)는 앞서 살펴보았던 특징들을 모아서 벡터로 표현한 것 이다. 엑셀 파일과 같은 테이블로 구성된 데이터셋의 각 행(row)도 이에 해당할 수 있다.  \n",
    "각 열(column)은 벡터가 되면 차원을 이루고 벡터의 각 차원은 어떤 속성에 대한 수치를 나타낼 수 있다.  \n",
    "수치가 비슷할수록 비슷한 샘플이라고 생각할 수 있을 것이다. 즉, 특징 벡터를 구성하면 이를 통해 샘플 사이의 거리(유사도)를 계산할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.2 원 핫 인코딩"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 연속 vs 카테고리 값\n",
    "\n",
    "우리가 다루는 데이터 샘플은 보통 연속 값과 카테고리 값 두 가지로 구성된다.  \n",
    "연속 값은 키, 몸무게 와 같은 실수로 표현될 수 있는 값이다. 카테고리 값은 보통 이산 값이며 단어나 클래스로 표현된다.  \n",
    "연속 값은 비슷한 값이라면 서로 비슷하다는 의미를 지니지만, 카테고리 값은 비슷한 값일지라도 서로 상관 없다는 의미를 지닌다.  \n",
    "따라서 우리는 카테고리 값을 특징 벡터로 표현할 때에 인덱스 값으로 표기하는 대신 다른 방법을 선택해야 한다. 코사인 유사도나 유클리디안 거리에서 이상한 계산이 이루어지기 때문."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 원 핫 인코딩\n",
    "\n",
    "원 핫 인코딩이란 크기가 의미를 갖는 정수로 나타내는 대신에 한개의 1과 n-1개의 0으로 나누어진 n차원의 벡터로 나타내는 방법을 의미한다.  \n",
    "원 핫 벡터들은 서로 직교하고, 서로 다른 두 벡터의 코사인 유사도는 항상 0이며 유클라디안 거리는 루트2 이다.  \n",
    "\n",
    "이처럼 벡터 대부분의 차원이 0인 경우를 희소 벡터라고 부른다. 이와 반대되는 개념은 고밀도 벡터이다.  \n",
    "앞서 본것처럼 희소 벡터의 경우에는 유사도 계산이나 거리 계산을 통해 샘플 사이의 관게를 파악하는 데 어려움을 겪을 수 있다. 원 핫 벡터는 희소 벡터의 장점이라고 할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 단어 임베딩\n",
    "\n",
    "자연어 처리는 단어를 데이터로 다루는 대표적인 분야이다. 따라서 단어를 모델에 입력으로 넣어주기 위해서 어쩔 수 없이 원 핫 인코딩 벡터를 활용해야 한다.  \n",
    "하지만 단어의 개수는 매우 많기 때문에 차원이 커져서 비효율 적이며, 단어 사이의 유사도를 표현할 수 없다.  \n",
    "\n",
    "이때 필요한 것이 단어 임베딩이다. 단어 임베딩 기법을 통해 원 핫 벡터로 표현된 단어를 고밀도 벡터로 표현 할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16.3 차원 축소\n",
    "\n",
    "굳이 높은 차원의 공간에서 데이터를 표현할 필요가 없다. 따라서 차원 축소를 진행한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 선형 차원 축소: 주성분분석[PCA]\n",
    "PCA는 가장 널리 사용되는 차원 축소 방법 중의 하나로, 고차원의 공간에 샘플들이 분포 하고 있을 때, 분포를 잘 설명하는 새로눈 축(axis)를 찾아내는 과정을 말한다.  \n",
    "차원 축소를 수행하면 앞과 같이 희소한 벡터들이 존재할 때 좀더 밀도 높은 표현의 벡터로 나타낼 수 있게 된다.\n",
    "\n",
    "<img src = \"표현함수1.jpg\" width = \"400\" height = \"400\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
