{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19.1 순환신경망 소개"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"rnn1.jpg\" width = \"400\" height = \"200\">  \n",
    "\n",
    "위 그림에서 x(t) 또는 h(t)라는 표현을 보면 t가 추가되어 순서를 표기하고 있음을 알 수 있다.  \n",
    "그리고 그 t가 끝에 다다르면 비로소 y=h(t)가 되어 출력값을 얻게 된다.  \n",
    "h(t)를 얻기 위해서 x(t)뿐만 아니라 h(t-1)도 함께 함수의 입력으로 주어져야 한다는 것 이다.  \n",
    "즉, 이전 순서에서의 상태 결과인 h(t-1)을 현재 입력 x(t)와 함께 함수에 넣어주어 현재 상태 결과인 h(t)를 구하도록 되어있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이런 신경망의 형태를 순환신경망(RNN)이라고 부른다.  \n",
    "기존 신경망은 주로 테이블 데이터나 이미지 데이터를 다루는 데 사용되었지만 RNN은 자연어 처리와 같이 순서 정보가 담긴 데이터나 시계열 데이터를 다루는 데 적합하다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19.2 RNN 한 걸음씩 들여다보기"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 기본적인 RNN의 구조"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN은 다음의 수식과 같이 네개의 가중치 파라미터를 갖는다.\n",
    "\n",
    "<img src = \"rnn1.jpg\" width = \"400\" height = \"200\">\n",
    "\n",
    "w(ih),b(ih)는 입력 x(t)에 곱해지고 더해지는 파라미터가 되고, w(hh),b(hh)는 이전 순서의 결과값인 h(t-1)에 곱해지고 더해지는 파라미터가 된다.\n",
    "\n",
    "이 연산 결괏값에 하이퍼볼릭 탄젠트를 통과시켜 현재 순서의 h(t)를 얻을 수 있다.  \n",
    "이 h(t)를 RNN의 은닉 상태라고 부른다.  \n",
    "\n",
    "<img src = \"rnn3.jpg\" width = \"400\" height = \"100\">  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN을 학습시키는 방법은 여러가지지만 모든 순서의 결괏값(은닉 상태)h(t)들을 출력으로 취급하여 학습하는 것이다.  \n",
    "정답 또한 순서 데이터로 y={y(1)...y(T)}와 같이 갖고 있어야 한다.  \n",
    "다음 그림과 같이 h(t)->y^(t)가 되어 실제 정답과 비교하는 손실 함수를 구성할 수 있다.  \n",
    "\n",
    "<img src = \"rnn4.jpg\" width = \"400\" height = \"200\">  \n",
    "\n",
    "이러한 형태의 RNN을 활용하면 가변 길이의 순서데이터를 다룰 수 있다.  \n",
    "순서 데이터는 각 순서에 나타나는 값에 따라 앞뒤 순서의 값이 영향을 받을 뿐만 아니라 전체 순서 데이터의 의미가 결정되기도 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. RNN의 입출력 텐서 형태"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 RNN의 입력 텐서 모양을 시각화 한 것 이다.\n",
    "\n",
    "<img src = \"rnn5.jpg\" width = \"400\" height = \"200\">  \n",
    "\n",
    "하나의 순서에 대한 텐서를 x(t)라고 할 때 앞 그림의 왼쪽과 같은 텐서가 존재할 것이고, 순서가 n개 있다면 오른쪽 그림과 같은 텐서가 될 것이다.  \n",
    "텐서의 첫 번째 차원은 미니배치 내의 인덱스를 기리키고, 두 번째 차원은 순서 정보를 가지며 마지막 차원은 입력 벡터가 된다. \n",
    "다음 그림은 RNN의 입력이 들어간 후 반환되는 출력 텐서이다.  \n",
    "\n",
    "<img src = \"rnn6.jpg\" width = \"400\" height = \"200\">  \n",
    "\n",
    "RNN의 출력 텐서 형태에서는 순서 정보에 대한 차원이 빠지지만, (batch_size,hidden_size) = (batch_size,1,hidden_size)이므로 여전히 같은 텐서의 형태라고 봐도 무방하다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 다계층 순환신경망"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "선형 계층이나 합성곱 계층을 여러층 쌓아서 심층신경망을 만들었던 것처럼 RNN도 여러층을 쌓아서 깊게 만들 수 있다.  \n",
    "이것을 다계층 순환신경망이라고 부른다.  \n",
    "다계층 순환신경망도 각 순서마다 y^(t)를 반환하며, 실제 정답 y(t)와 비교해서 손실 함수를 계산하는 것을 볼 수 있다.  \n",
    "\n",
    "단일 계층 순환신경망에서 오른쪽으로 빠지는 화살표를 은닉 상태h(t)라고 했었고, 이것이 곧 출력 y^(t)라고 했다.  \n",
    "하지만 다계층 순환신경망에서는 여러 층이 동시에 h(t)를 반환하기 때문에 y^(t)와 h(t)가 같을 수 없다.\n",
    "\n",
    "<img src = \"rnn7.jpg\" width = \"400\" height = \"300\">  \n",
    "\n",
    "수식을 살펴보면 각 계층마다 h(t,l)을 반환하고, 마지막 계층의 h(t,l)을 받아서 y^(t)로 삼고 있음을 볼 수 있다.  \n",
    "즉, 다계층 순환신경망에서 은닉 상태는 모델의 출력이 되지 않는다.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음 그림에서 빨간색 점선 네모로 표시된 부분이 다계층 순환신경망의 입력이 되는 부분이다.\n",
    "\n",
    "<img src = \"rnn8.jpg\" width = \"400\" height = \"200\">  \n",
    "\n",
    "입력 형태는 단일 계층 순환신경망의 입력 텐서의 형태와 같다.  \n",
    "다음은 출력 텐서이다.  \n",
    "\n",
    "<img src = \"rnn9.jpg\" width = \"400\" height = \"200\">  \n",
    "\n",
    "마찬가지로 단일 계층 순환신경망의 출력 텐서와 형태가 같다.  \n",
    "하지만 단일 계층 순환신경망에서는 은닉 상태가 곧 출력이었지만 다계층 순환신경망에서는 출력과 은닉 상태가 다르다.  \n",
    "다음은 다계층 순환신경망의 은닉 상태를 빨간색 점선 네모로 표시한 그림이다.  \n",
    "\n",
    "<img src = \"rnn10.jpg\" width = \"400\" height = \"200\">  \n",
    "\n",
    "위 그림에서 볼 수 있듯이 빨간색 점선 네모의 위치가 달라졌고, 텐서의 모양도 다르다.  \n",
    "가장 주목할 부분은 앞의 출력 텐서는 순서 정보가 두 번째 차원에 들어가있는 반면에 은닉 상태 텐서는 어떤 특정 순서 상에서 얻을 것이기 때문에 순서 정보가 텐서에 없다.  \n",
    "대신 가장 첫 번째 차원에 미니배치와 관련된 정보가 아니라 계층 순서에 대한 정보가 담겨있다.  \n",
    "그리고 두 번째 차원에 미니배치에 대한 정보가 담겨있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 은닉 상태"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "은닉 상태에는 순환신경망이 현재 순서까지 입력 x1 ... x(t)들을 받아오면서 자신의 상태를 업데이트한 기억을 갖고 있다고 볼 수 있다.  \n",
    "은닉 상태는 신경망을 통과하는 값일 뿐이며 학습하는 가중치 파라미터가 아니다.  \n",
    "사람과 비유하면 우리가 어떤 입력을 받아 생각하는 것은 가중치 파라미터와 연산을 하는 것이라고 볼 수 있다.  \n",
    "행동은 모델의 출력 y^(t)라고 볼 수 있고, 우리가 기억하는 것이 모델의 은닉 상태  h(t)라고 볼 수 있을 것이다.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 양방향 다계층 순환신경망"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 살펴본 RNN은 한 방향으로만 은닉 상태가 흐르는 모델이었다.  즉, 현재 순서의 은닉 상태는 이전 순서의 은닉 상태와 현재 입력에만 의존한다.  \n",
    "이런 모델을 자기회귀 모델이라고 부른다. 하지만 이번에는 역방향이 추가된 양방향 순환신경망을 살펴본다.  \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"rnn12.jpg\" width = \"400\" height = \"200\">  \n",
    "\n",
    "양방향 다계층 순환신경망의 각 층의 RNN셀은 이전 계층의 정방향과 역뱡향 결과물을 입력으로 받는다. 그리고 정방향 RNN셀은 이전 순서의 은닉 상태를 받고 RNN셀은 미래 순서의 은닉 상태를 받는다.\n",
    "\n",
    "모델의 입력 텐서 모양은 앞에서 살펴보았던 모델들의 입력 텐서 모양과 똑같다. 그리고 출력 텐서 모양은 다음과 같다.\n",
    "\n",
    "<img src = \"rnn13.jpg\" width = \"400\" height = \"200\">  \n",
    "\n",
    "위 그림의 빨간색 점선으로 표시된 부분에서 볼 수 있듯이 출력 텐서는 마지막 계층의 정방향과 역방향 RNN 셀로부터 출력을 수집한다.   \n",
    "따라서 텐서 형태의 마지막 차원이 hidden_size x #drection로 되어 기존의 두배가 된 것을 볼 수 있다.\n",
    "\n",
    "보통 단방향 순환신경망은 은닉 상태를 따로 저장했다가 이어 연산을 진행하는 등의 작업을 수행하는 경우도 많아 은닉 상태를 직접 다룰 일이 많지만  \n",
    "양방향 순환신경망은 중간에 은닉 상태를 접근할 일이 거의 없다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19.3 순환신경망 활용 사례\n",
    "\n",
    "<img src = \"rnn14.jpg\" width = \"400\" height = \"250\">  \n",
    "\n",
    "RNN이 가장 많이 활용되는 분야는 단연 자연아 처리이다. 자연어 처리에서 문장은 출현 단어 개수가 가변적이며 단어의 출현 순서에 따라 의미가 결정된다.  \n",
    "이처럼 입력과 출력의 종류에 따라 활용 타입을 정의할 수 있지만 모델링하고자 하는 대상의 자기회귀 성격 여부에 따라 활용 방법이 달라지기도 한다.  \n",
    "자기회귀란 현재 상태가 과거 상태에 의존하여 정해지는 경우를 말한다.  \n",
    "따라서 정보 흐름의 방향이 생기게 되고 이것을 모델링 하기 위해서는 단방향 순환신경망을 사용할 수 밖에 없다.  \n",
    "문장 전체를 놓고 문장이 속하는 클래스(긍정 or 부정)를 정하는 문제는 이미 분류기에 들어가기 전에 문장 전체가 주어진다.  \n",
    "또한 클래스는 문장 전체에 대해서 단 한번 예측이 수행되기 때문에 자기회기 성격을 가진다고 볼 수 없다.\n",
    "\n",
    "<img src = \"rnn15.jpg\" width = \"400\" height = \"150\"> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 다대일 형태"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다대일 형태는 우리가 학습할 데이터에서 입력은 순서 정보를 갖고 있고, 출력은 순서 정보가 없는 경우이다.  \n",
    "이 케이스는 비자기회귀 성격을 갖는다고 볼 수 있다.  \n",
    "\n",
    "<img src = \"rnn16.jpg\" width = \"400\" height = \"300\"> \n",
    "\n",
    "앞의 그림에서 볼 수 있듯이 양방향 순환신경망을 사용할 수 있고, 보통 마지막 순서 출력을 활용하여(처음 순서 출력을 이용해도 아랑곳 x) 모델의 예측 값 y^으로 삼고 원래 목푯값인 y와 비교하여 손실 값을 계산한다.  \n",
    "텍스트 분류가 가장 좋은 예제라고 볼 수 있다. 텍스트 문장을 정해진 기준에 따라 쪼개어 순환신경망의 입력으로 삼아 각 순서에 맞게 나누어 넣어준다.  \n",
    "그럼 마지막 계층의 순서에서 나온 출력을 비선현 활성 함수, 선형 계층, 그리고 소프트맥스 함수를 거치도록 하여 각 클래스별 확률 값으로 변환할 수 있다.  \n",
    "그리고 분류 문제이기 때문에 교차 엔트로피 손실 함수를 통과시켜 손실 값을 구할 수 있을 것이다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 다대다 형태"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다대다 형태는 입력과 출력의 순서 개수가 같아야 하며 각 순서가 입력에 대응되는 형태여야 한다.  \n",
    "만약 순서 개수가 다르거나 대응이 다르게 되면 일대다 형태가 되어야 한다.  \n",
    "다대다 형태도 비자기회귀 성격을 갖는다.\n",
    "\n",
    "<img src = \"rnn17.jpg\" width = \"400\" height = \"300\"> \n",
    "\n",
    "각 순서의 입력 x(t)마다 대응되는 목푯값 y(t)가 존재하는 것을 볼 수 있고, 모델에서도 각 입력에 대응되는 y^(t)가출력되는 것을 볼 수 있다.  \n",
    "그러면 모든 순서의 출력값과 목푯값의 차이를 합쳐서 손실값을 계산할 수 있다.  \n",
    "\n",
    "이러한 대다대 형태의 가장 흔한 예제로 형태소 분석이 있다. 문장 내 토큰들에 대해서 각각 형태소가 태깅되어야 하기 때문에 입력 순서들에 1:1로 출력값이 존재해야 하기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
