{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cca8839",
   "metadata": {},
   "source": [
    "# 4.1 행렬 곱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99960d54",
   "metadata": {},
   "source": [
    "### 1. 행렬 곱\n",
    "\n",
    "행렬 A와B가주어져 있고, 이 둘을 곱한다고 가정해볼 때, A의 행요소(row element)들을 B의 열요소(column element)들에 각각 곱한 후 더한 값을 행렬에 요소로 결정하게 된다.\n",
    "\n",
    "### A 의 열의 개수와 B의 행의 개수는 같아야 한다는 제약조건이 발생한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9908163a",
   "metadata": {},
   "source": [
    "예를 들어 A는 2x3 행렬이고, B는 3x2 행렬일 때, AB는 2x2 행렬이 된다. 이를 수식으로 표현하면 다음과 같다.\n",
    "\n",
    "<img src = \"행렬곱1.jpg\" width = \"400\" height = \"400\">\n",
    "\n",
    "이러한 행렬의 곱셈 과정은 내적(inner product)또는 닷 프로덕트(dot product)라고 부릅니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85aa361",
   "metadata": {},
   "source": [
    "### 2. 벡터 행렬 곱\n",
    "\n",
    "벡터가 곱셈의 앞에 위치할 경우, 전치(transpose)를 통해 행과 열을 바꿔 표현하여 곱셈을 수행한다.  \n",
    "벡터의 경우, 두 번째 차원의 크기(요소의 개수)가 1인 행렬과 똑같은 형태로 취급할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "313c4951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# practice 4.2 행렬 곱\n",
    "import torch\n",
    "\n",
    "x = torch.FloatTensor([[1,2],\n",
    "                       [3,4],\n",
    "                       [5,6]])\n",
    "y = torch.FloatTensor([[1,2],\n",
    "                       [1,2]])\n",
    "print(x.size(), y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c879282",
   "metadata": {},
   "source": [
    "파이토치의 matmul함수를 이용하면 행렬 곱을 수행 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80bf146a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x,y)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f8bbc6",
   "metadata": {},
   "source": [
    "딥러닝을 수행할 때, 보통 여러 샘플을 동시에 병렬 계산하곤 한다. 이때, bmm(Batch Matrix Multiplication)함수가 이 역할을 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a10070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# practice 4.2.1 배치 행렬곱\n",
    "import torch\n",
    "\n",
    "x = torch.FloatTensor(3,3,2)\n",
    "y = torch.FloatTensor(3,2,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3856bae6",
   "metadata": {},
   "source": [
    "3x3x2 크기의 텐서는 3x2 크기의 행렬이 3개 있는 것이라고 볼 수 있습니다.  \n",
    "마찬가지로 3x2x3 크기의 텐서는 2x3크기의 행렬이 3개 있는 것과 같다.  \n",
    "여기에서 bmm 함수를 사용하여 행렬 곱이 3번 수행되는 연산을 병렬로 동시에 진행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13a71cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "z = torch.bmm(x,y)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7c6d18",
   "metadata": {},
   "source": [
    "결과물의 크기가 3x3 크기의 행렬이 3개 있는 3x3x3 형태로 나오는 것을 볼 수 있다.  \n",
    "이처럼 bmm 함수는 마지막 2개의 차원을 행렬 취급하여 병렬로 행렬 곱 연산을 수행한다.  \n",
    "bmm 함수를 적용하기 위해서 마지막 2개의 차원을 제외한 다른 차원의 크기는 동일해야 한다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46f324a1",
   "metadata": {},
   "source": [
    "# 4.3 선형 계층\n",
    "\n",
    "선형 계층은 뒤에서 다룰 심충신경망(deep neural networks)의 가장 기본적인 구성 요소이다.\n",
    "\n",
    "<img src = \"선형계층1.jpg\" width = \"300\" height = \"300\">\n",
    "\n",
    "또한, 선형 계층은 하나의 함수로 볼 수 있는데 4개의 입력을 받아 3개의 출력을 반환하는 함수로 생각할 수 있다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5524c03e",
   "metadata": {},
   "source": [
    "### 1. 선형 계층 함수의 동작 방식\n",
    "\n",
    "해당 함수는 가중치 파라미터(weight parameter)를 가지고 있으며, 이것에 의해 함수의 동작이 결정된다.\n",
    "\n",
    "<img src = \"선형계층2.jpg\" width = \"400\" height = \"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad982fd7",
   "metadata": {},
   "source": [
    "앞에 그림에서 W 에는 총 4x3=12 가지의 가중치 파라미터가 존재하며 이는 다음과 같은 수식으로 표현이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0175bca0",
   "metadata": {},
   "source": [
    "<img src = \"선형계층3.jpg\" width = \"400\" height = \"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca556cb",
   "metadata": {},
   "source": [
    "b에는 총 3가지의 가중치 파라미터가 존재하며 다음과 같이 수식으로 표현이 가능하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83a814",
   "metadata": {},
   "source": [
    "<img src = \"선형계층4.jpg\" width = \"400\" height = \"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af78a66a",
   "metadata": {},
   "source": [
    "이 동작 방식은 행렬 곱셈과 벡터의 덧셈으로 나타낼 수 있기 때문에 일반화 하여 다음과 같은 수식으로 표현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bdb020",
   "metadata": {},
   "source": [
    "<img src = \"선형계층5.jpg\" width = \"500\" height = \"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629472c",
   "metadata": {},
   "source": [
    "입력 벡터 x는 n차원 실수 벡터이며, 출력벡터 y는 m차원의 실수 벡터 이다. 따라서 n차원을 m 차원으로 변환해주기 위해서 W는 nxm 차원의 행렬이 되어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c5f4e2",
   "metadata": {},
   "source": [
    "만약 수 백만개의 입력 벡터가 주어졌다고 했을 때, 단순히 순차적으로 처리한다기보단 다수의 입력을 처리하기 위한 병렬 연산으로 생각해 볼 수도 있다.  \n",
    "N개의 n차원 벡터를 모아서 Nxn 크기의 행렬로 만들 수 있다. 이것을 \"미니배치\"라고 부르겟다.  \n",
    "선형 계층에서 미니배치 행렬을 처리하기 위한 수식은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef06bad",
   "metadata": {},
   "source": [
    "<img src = \"선형계층6.jpg\" width = \"500\" height = \"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ee4fd8",
   "metadata": {},
   "source": [
    "입력을 N개 모아서 미니배치 행렬로 넣어주었기 때문에 출력도 N개의 m차원 벡터가 모여 Nxm 크기의 행렬이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1849518",
   "metadata": {},
   "source": [
    "### 2. 선형 계층의 의미\n",
    "\n",
    "선형 계층은 행렬 곱셈과 벡터의 덧셈으로 이루어져 있기 때문에 선형 변환이라고 볼 수 있다.  \n",
    "선형 데이터에 대한 관계를 분석하거나, 선형 함수를 근사 계산할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9fab1d",
   "metadata": {},
   "source": [
    "# 4.4 선형 계층 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de19b0d1",
   "metadata": {},
   "source": [
    "### 1. 직접 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f339f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 직접 구현하기\n",
    "import torch\n",
    "\n",
    "W = torch.FloatTensor([[1,2],\n",
    "                       [3,4],\n",
    "                       [5,6]])\n",
    "b = torch.FloatTensor([2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a66d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(x,W,b):\n",
    "    y = torch.matmul(x,W)+b\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4f73da",
   "metadata": {},
   "source": [
    "matmul함수와 브로드캐스팅을 이용한 + 연산자로 linear 함수를 만들어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af50d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.FloatTensor(4,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5794d5c6",
   "metadata": {},
   "source": [
    "3개의 요소를 갖는 4개의 샘플을 행렬로 나타내면 x와 같이 4x3 크기의 행렬이 될 것이다. 이것을 다음 코드처럼 함수를 활용하여 선형 계층을 통과시킬 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e0c63af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "y = linear(x,W,b)\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7396b6",
   "metadata": {},
   "source": [
    "### 2. torch.nn.Module 클래스 상속받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c307fb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.nn.Module 클래스 상속받기\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa0bcbb",
   "metadata": {},
   "source": [
    "nn.Module을 상속받은 MyLinear라는 클래스를 정의한다. nn.Module을 상속받은 클래스는 보통 2개의 메소드, __init__과 forward를 오버라이드 한다.  \n",
    "__init__ 함수는 계층 내부에서 필요한 변수를 미리 선언하고 있으며 심지어 또 다른 계층을 소유하도록 할 수 있다.  \n",
    "forward 함수는 계층을 통과하는데 필요한 계산 수행을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f52f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=3, output_dim=2):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = torch.FloatTensor(input_dim, output_dim)\n",
    "        self.b = torch.FloatTensor(output_dim)\n",
    "        \n",
    "    # you should override 'forward' method to implement detail.\n",
    "    # the input arguments and outputs can be designed as you wish.\n",
    "    def forward(self, x):\n",
    "        #|x| = (batch_size, input_dim)\n",
    "        y = torch.matmul(x, self.W) + self.b\n",
    "        #|y| = (batch_size, input_dim) * (input_dim, output_dim)\n",
    "        #    = (batch_size, output_dim)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "000d817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = MyLinear(3,2)\n",
    "\n",
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d13e3c",
   "metadata": {},
   "source": [
    "여기서 중요한 점은 forward 함수를 따로 호출하지 않고, 객체명에 바로 괄호를 열어 텐서 x를 인수로 넘겨주었다는 것이다.  \n",
    "nn.Module의 상속받은 객체는 __call__ 함수와 forward가 매핑 되어있어 forward를 따로 부를 필요가 없다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3633600a",
   "metadata": {},
   "source": [
    "### 3. 올바른 방법: nn.Parameter 활용하기\n",
    "\n",
    "다음과 같이 텐서 선언 이후에 nn.Parameter로 감싸준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4972581",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=3, output_dim=2):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.W = nn.Parameter(torch.FloatTensor(input_dim, output_dim))\n",
    "        self.b = nn.Parameter(torch.FloatTensor(output_dim))\n",
    "        \n",
    "    # you should override 'forward' method to implement detail.\n",
    "    # the input arguments and outputs can be designed as you wish.\n",
    "    def forward(self, x):\n",
    "        #|x| = (batch_size, input_dim)\n",
    "        y = torch.matmul(x, self.W) + self.b\n",
    "        #|y| = (batch_size, input_dim) * (input_dim, output_dim)\n",
    "        #    = (batch_size, output_dim)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bea7e544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1.0741e-05, 1.6821e-04],\n",
      "        [4.1490e-08, 5.2944e-08],\n",
      "        [8.4336e-07, 3.3710e-06]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in linear.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62e81c9",
   "metadata": {},
   "source": [
    "### 4. nn.Linear 활용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ee44c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(3,2)\n",
    "\n",
    "y = linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "052c8e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.5241, -0.0753,  0.4215],\n",
      "        [-0.0226, -0.3614, -0.2554]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.5456, -0.1156], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for p in linear.parameters():\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa6706e",
   "metadata": {},
   "source": [
    "nn.Module을 상속받아 정의한 나만의 계층 클래스는 내부의 nn.Module 하위 클래스를 소유할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff73ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim=3, output_dim=2):\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    # you should override 'forward' method to implement detail.\n",
    "    # the input arguments and outputs can be designed as you wish.\n",
    "    def forward(self, x):\n",
    "        #|x| = (batch_size, input_dim)\n",
    "        y = torch.matmul(x, self.W) + self.b\n",
    "        #|y| = (batch_size, input_dim) * (input_dim, output_dim)\n",
    "        #    = (batch_size, output_dim)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c7fcda",
   "metadata": {},
   "source": [
    "앞의 코드는 nn.Module을 상속받아 MyLinear 클래스를 정의하고 있는데, __init__ 함수 내부에는 nn.Linear를 선언하여 self.linear에 저장하고, forward 함수에서는 self.linear에 텐서 x를 통과시킨다.  \n",
    "즉, 이 코드도 선형 계층을 구현한 것 이라 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bf083e",
   "metadata": {},
   "source": [
    "# 4.5 GPU 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1426babc",
   "metadata": {},
   "source": [
    "### 1. Cuda 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8bba7643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cuda.FloatTensor(2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ec66c2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.4013e-45, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.4013e-45, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텐서의 cuda 함수를 통해 CPU 메모리상에 선언된 텐서를 GPU로 복사하는 방법\n",
    "x = torch.FloatTensor(2,2)\n",
    "print(x)\n",
    "x = x.cuda()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c0b150",
   "metadata": {},
   "source": [
    "Cuda 함수는 텐서 뿐만 아니라 nn.Module 하위 클래스 객체에도 똑같이 적용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0497511d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=2, bias=True)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "layer = nn.Linear(2,2)\n",
    "layer.cuda(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544a2c75",
   "metadata": {},
   "source": [
    "주의 해야할 점은, 텐서는 cuda 함수를 통해 원하는 디바이스로 복사가 되지만, nn.Module 하위 클래스 객체의 경우 복사가 아닌 이동이 수행된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be701f",
   "metadata": {},
   "source": [
    "### 2. 서로 다른 장치간 연산\n",
    "\n",
    "서로 다른 장치에 올라가있는 텐서 또는 nn.Module의 하위 클래스 객체끼리는 연산이 불가능하다.  \n",
    "CPU와 GPU에 위치한 텐서들 끼리 연산이 불가능 할 뿐만 아니라, 0번 GPU와 1번 GPU 사이의 연산도 불가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be7beb71",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22248\\3026915322.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor(2,2)\n",
    "x + x.cuda(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57b2917",
   "metadata": {},
   "source": [
    "### 3. Cpu 함수\n",
    "\n",
    "반대로 필요에 따라 GPU 메모리 상에 있는 텐서를 CPU 메모리로 복사해야 하는 상황이 생길 때, cpu함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "715fe762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cuda.FloatTensor(2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "def17004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.cpu()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932a2e01",
   "metadata": {},
   "source": [
    "### 4. To 함수\n",
    "\n",
    "to 함수는 원하는 디바이스의 정보를 담은 객체를 인자로 받아, 함수 자신을 호출한 객체를 해당 디바이스로 복사(이동) 시킨다.  \n",
    "디바이스 정보를 담은 객체는 torch.device를 통해 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fcecb0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_device = torch.device('cpu')\n",
    "gpu_device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "beb89e09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., nan],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor(2,2)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "732cd265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., nan],\n",
       "        [0., 0.]], device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to(gpu_device)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1be854e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., nan],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.to(cpu_device)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bcf6f6",
   "metadata": {},
   "source": [
    "### 5. Device 속성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6ffd5f93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cuda.FloatTensor(2,2)\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25de4d4a",
   "metadata": {},
   "source": [
    "nn.Module의 하위 클래스 객체는 해당 속성을 갖고 있지 않다.  \n",
    "모델이 어느 장치에 올라가 있는지 알고 싶다면 다음과 같은 방법을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4582a11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = nn.Linear(2,2)\n",
    "next(layer.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4979ea0c",
   "metadata": {},
   "source": [
    "parameters 함수를 통해 모델 내의 파라미터에 대한 이터레이터를 얻은 후, 첫 번째 파라미터 텐서의 device 속성에 접근한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
